// services/unifiedAIService.ts
// Servicio Unificado de IA con Fallback Autom√°tico
// Soporta Claude, Gemini y OpenAI con cambio autom√°tico si uno falla

import { askAssistant as claudeAskAssistant, analyzeDelayPatterns } from './claudeService';
import { askAssistant as geminiAskAssistant } from './geminiService';
import { guideHistoryService } from './guideHistoryService';
import { centralBrain } from './brain/core/CentralBrain';
import { memoryManager } from './brain/core/MemoryManager';
import { contextManager } from './brain/core/ContextManager';

// ============================================
// TIPOS E INTERFACES
// ============================================

export type AIProvider = 'claude' | 'gemini' | 'openai';

export interface AIConfig {
  provider: AIProvider;
  temperature: number;
  maxTokens: number;
  systemPrompt: string;
}

export interface AIResponse {
  text: string;
  provider: AIProvider;
  confidence: number;
  processingTime: number;
  fallbackUsed: boolean;
  error?: string;
  metadata?: {
    tokensUsed?: number;
    model?: string;
  };
}

export interface ConversationContext {
  shipments: any[];
  guideHistory: string;
  brainSummary: string;
  operationalContext: string;
  recentQueries: string[];
}

// ============================================
// CONFIGURACI√ìN POR DEFECTO
// ============================================

const DEFAULT_CONFIGS: Record<AIProvider, AIConfig> = {
  claude: {
    provider: 'claude',
    temperature: 0.7,
    maxTokens: 4096,
    systemPrompt: `Eres un EXPERTO EN LOG√çSTICA DE √öLTIMA MILLA EN COLOMBIA con 15+ a√±os de experiencia.
Trabajas para Litper Pro, una plataforma de gesti√≥n log√≠stica premium.

Tu conocimiento incluye:
- Todas las transportadoras colombianas (Inter Rapid√≠simo, Env√≠a, Coordinadora, TCC, Servientrega)
- Zonas de dif√≠cil acceso del pa√≠s
- Tiempos realistas de entrega por ciudad y regi√≥n
- Patrones de problemas comunes (novedades, devoluciones)
- Mejores pr√°cticas de atenci√≥n al cliente

Siempre respondes en ESPA√ëOL COLOMBIANO de forma profesional, clara y accionable.
Cuando hay datos de gu√≠as, los analizas y das recomendaciones espec√≠ficas.
Si no tienes suficiente informaci√≥n, pides los datos que necesitas.`,
  },
  gemini: {
    provider: 'gemini',
    temperature: 0.8,
    maxTokens: 4096,
    systemPrompt: `Eres un asistente de log√≠stica de Litper Pro con capacidades de visi√≥n e im√°genes.
Especializado en an√°lisis de capturas de seguimiento y evidencias de entrega.
Respondes en espa√±ol de forma clara y √∫til.`,
  },
  openai: {
    provider: 'openai',
    temperature: 0.7,
    maxTokens: 4096,
    systemPrompt: `Eres un asistente profesional de log√≠stica para el mercado colombiano.
Ayudas con seguimiento de env√≠os, an√°lisis de datos y comunicaci√≥n con clientes.
Respondes de forma profesional en espa√±ol.`,
  },
};

// Orden de fallback
const FALLBACK_ORDER: AIProvider[] = ['claude', 'gemini', 'openai'];

// ============================================
// SERVICIO UNIFICADO DE IA
// ============================================

class UnifiedAIService {
  private configs: Record<AIProvider, AIConfig> = { ...DEFAULT_CONFIGS };
  private currentProvider: AIProvider = 'claude';
  private recentQueries: string[] = [];
  private providerStatus: Record<AIProvider, { available: boolean; lastError?: string }> = {
    claude: { available: true },
    gemini: { available: true },
    openai: { available: true },
  };

  constructor() {
    console.log('ü§ñ [UnifiedAI] Servicio inicializado');
  }

  // ==================== CONFIGURACI√ìN ====================

  /**
   * Establecer proveedor de IA
   */
  setProvider(provider: AIProvider): void {
    this.currentProvider = provider;
    console.log(`ü§ñ [UnifiedAI] Proveedor cambiado a: ${provider}`);
  }

  /**
   * Obtener proveedor actual
   */
  getProvider(): AIProvider {
    return this.currentProvider;
  }

  /**
   * Actualizar configuraci√≥n de un proveedor
   */
  updateConfig(provider: AIProvider, config: Partial<AIConfig>): void {
    this.configs[provider] = { ...this.configs[provider], ...config };
  }

  /**
   * Obtener estado de proveedores
   */
  getProvidersStatus(): Record<AIProvider, { available: boolean; lastError?: string }> {
    return { ...this.providerStatus };
  }

  // ==================== CONSTRUCCI√ìN DE CONTEXTO ====================

  /**
   * Construir contexto completo para la IA
   */
  buildContext(shipments: any[]): ConversationContext {
    // Sincronizar gu√≠as con el servicio de historial
    if (shipments.length > 0) {
      guideHistoryService.syncFromShipments(shipments);
    }

    // Obtener contexto del historial de gu√≠as
    const guideHistory = guideHistoryService.getAIContext();

    // Obtener resumen del cerebro
    const brainSummary = this.getBrainSummary();

    // Obtener contexto operacional
    const operationalContext = this.getOperationalContext();

    return {
      shipments,
      guideHistory,
      brainSummary,
      operationalContext,
      recentQueries: this.recentQueries.slice(-5),
    };
  }

  private getBrainSummary(): string {
    const summary = centralBrain.getSummary();
    return `
ESTADO DEL SISTEMA:
- Salud: ${summary.health}
- Env√≠os registrados: ${summary.shipments}
- Entregados: ${summary.delivered}
- Con problemas: ${summary.issues}
- Retrasados: ${summary.delayed}
- Entradas en memoria: ${summary.memoryEntries}
`.trim();
  }

  private getOperationalContext(): string {
    const ctx = contextManager.getContext();
    return `
CONTEXTO OPERACIONAL:
- Usuario: ${ctx.user?.role || 'operador'}
- Tab activo: ${ctx.session?.activeTab || 'seguimiento'}
- Gu√≠as seleccionadas: ${ctx.session?.selectedShipments?.length || 0}
- Score de performance: ${ctx.operational?.performanceScore || 0}%
`.trim();
  }

  // ==================== CHAT PRINCIPAL ====================

  /**
   * Enviar mensaje a la IA con contexto completo
   */
  async chat(
    message: string,
    shipments: any[] = [],
    options?: {
      provider?: AIProvider;
      temperature?: number;
      includeHistory?: boolean;
    }
  ): Promise<AIResponse> {
    const startTime = Date.now();
    const provider = options?.provider || this.currentProvider;

    // Agregar a queries recientes
    this.recentQueries.push(message);
    if (this.recentQueries.length > 10) {
      this.recentQueries.shift();
    }

    // Construir contexto
    const context = this.buildContext(shipments);

    // Construir prompt enriquecido
    const enrichedPrompt = this.buildEnrichedPrompt(message, context);

    // Intentar con el proveedor seleccionado
    let response = await this.callProvider(provider, enrichedPrompt, context);

    // Si falla, intentar fallback
    if (response.error && !response.fallbackUsed) {
      console.log(`ü§ñ [UnifiedAI] ${provider} fall√≥, intentando fallback...`);
      response = await this.tryFallback(provider, enrichedPrompt, context);
    }

    // Guardar en memoria para aprendizaje
    this.saveInteraction(message, response);

    return {
      ...response,
      processingTime: Date.now() - startTime,
    };
  }

  private buildEnrichedPrompt(message: string, context: ConversationContext): string {
    const parts: string[] = [];

    // Agregar contexto de gu√≠as si hay
    if (context.guideHistory) {
      parts.push('=== DATOS DE GU√çAS ACTUALES ===');
      parts.push(context.guideHistory);
      parts.push('');
    }

    // Agregar contexto del cerebro
    if (context.brainSummary) {
      parts.push('=== ESTADO DEL SISTEMA ===');
      parts.push(context.brainSummary);
      parts.push('');
    }

    // Agregar contexto operacional
    if (context.operationalContext) {
      parts.push('=== CONTEXTO OPERACIONAL ===');
      parts.push(context.operationalContext);
      parts.push('');
    }

    // Queries recientes para contexto de conversaci√≥n
    if (context.recentQueries.length > 0) {
      parts.push('=== PREGUNTAS RECIENTES ===');
      parts.push(context.recentQueries.join('\n'));
      parts.push('');
    }

    // Mensaje del usuario
    parts.push('=== PREGUNTA DEL USUARIO ===');
    parts.push(message);

    // Instrucciones finales
    parts.push('');
    parts.push('=== INSTRUCCIONES ===');
    parts.push('- Analiza los datos proporcionados');
    parts.push('- Da una respuesta espec√≠fica y accionable');
    parts.push('- Si mencionan gu√≠as espec√≠ficas, busca en los datos');
    parts.push('- Incluye n√∫meros y estad√≠sticas cuando sea relevante');
    parts.push('- Si necesitas m√°s informaci√≥n, pregunta');

    return parts.join('\n');
  }

  // ==================== LLAMADAS A PROVEEDORES ====================

  private async callProvider(
    provider: AIProvider,
    prompt: string,
    context: ConversationContext
  ): Promise<AIResponse> {
    try {
      let text: string;

      switch (provider) {
        case 'claude':
          text = await claudeAskAssistant(prompt, this.formatContextForClaude(context));
          break;

        case 'gemini':
          const geminiResponse = await geminiAskAssistant(prompt, context.shipments);
          text = geminiResponse.text;
          break;

        case 'openai':
          // OpenAI no est√° implementado directamente, usar Claude como proxy
          text = await claudeAskAssistant(`[Modo OpenAI] ${prompt}`, this.formatContextForClaude(context));
          break;

        default:
          throw new Error(`Proveedor no soportado: ${provider}`);
      }

      this.providerStatus[provider] = { available: true };

      return {
        text,
        provider,
        confidence: this.calculateConfidence(text),
        processingTime: 0,
        fallbackUsed: false,
      };
    } catch (error: any) {
      console.error(`ü§ñ [UnifiedAI] Error con ${provider}:`, error.message);

      this.providerStatus[provider] = {
        available: false,
        lastError: error.message,
      };

      return {
        text: '',
        provider,
        confidence: 0,
        processingTime: 0,
        fallbackUsed: false,
        error: error.message,
      };
    }
  }

  private async tryFallback(
    failedProvider: AIProvider,
    prompt: string,
    context: ConversationContext
  ): Promise<AIResponse> {
    // Obtener proveedores disponibles en orden de fallback
    const availableProviders = FALLBACK_ORDER.filter(
      p => p !== failedProvider && this.providerStatus[p].available
    );

    for (const provider of availableProviders) {
      console.log(`ü§ñ [UnifiedAI] Intentando fallback con: ${provider}`);

      const response = await this.callProvider(provider, prompt, context);

      if (!response.error) {
        return {
          ...response,
          fallbackUsed: true,
        };
      }
    }

    // Todos fallaron - respuesta de emergencia
    return {
      text: this.getEmergencyResponse(context),
      provider: 'claude',
      confidence: 0.3,
      processingTime: 0,
      fallbackUsed: true,
      error: 'Todos los proveedores de IA no est√°n disponibles',
    };
  }

  private getEmergencyResponse(context: ConversationContext): string {
    const stats = guideHistoryService.getStats();

    return `Lo siento, estoy teniendo dificultades t√©cnicas para procesar tu consulta.

**Mientras tanto, aqu√≠ tienes un resumen de tus datos:**

- Total de gu√≠as: ${stats.total}
- Tasa de entrega: ${stats.tasaEntrega.toFixed(1)}%
- Gu√≠as con novedad: ${stats.porEstado.novedad}
- En tr√°nsito: ${stats.porEstado.en_transito}
- En reparto: ${stats.porEstado.en_reparto}

**Acciones sugeridas:**
1. Revisa las gu√≠as con novedad en la pesta√±a de Seguimiento
2. Prioriza las gu√≠as con m√°s d√≠as en tr√°nsito
3. Contacta a las transportadoras para gu√≠as cr√≠ticas

¬øPuedo ayudarte con algo espec√≠fico mientras se restaura la conexi√≥n completa?`;
  }

  private formatContextForClaude(context: ConversationContext): string {
    const shipmentSummary = context.shipments.length > 0
      ? context.shipments.slice(0, 30).map(s =>
          `- Gu√≠a: ${s.id || s.guia}, Estado: ${s.status || s.estado}, Transportadora: ${s.carrier || s.transportadora}, Novedad: ${s.novelty || s.novedad || 'Sin novedad'}`
        ).join('\n')
      : 'No hay gu√≠as cargadas';

    return `
${context.guideHistory}

DETALLE DE GU√çAS:
${shipmentSummary}

${context.brainSummary}
${context.operationalContext}
`.trim();
  }

  private calculateConfidence(text: string): number {
    // Heur√≠stica simple para estimar confianza
    let confidence = 0.7;

    // M√°s largo = m√°s detallado = m√°s confianza
    if (text.length > 500) confidence += 0.1;
    if (text.length > 1000) confidence += 0.1;

    // Contiene n√∫meros espec√≠ficos = m√°s confianza
    if (/\d+/.test(text)) confidence += 0.05;

    // Contiene listas o estructura = m√°s confianza
    if (text.includes('-') || text.includes('‚Ä¢') || text.includes('1.')) confidence += 0.05;

    return Math.min(1, confidence);
  }

  private saveInteraction(query: string, response: AIResponse): void {
    memoryManager.remember('ai_interactions', {
      query,
      response: response.text.substring(0, 500),
      provider: response.provider,
      confidence: response.confidence,
      timestamp: new Date(),
    }, {
      type: 'SHORT_TERM',
      importance: 50,
    });
  }

  // ==================== FUNCIONES ESPECIALIZADAS ====================

  /**
   * An√°lisis de patrones de retraso (usa Claude espec√≠ficamente)
   */
  async analyzeDelays(shipments: any[]): Promise<any> {
    try {
      return await analyzeDelayPatterns(shipments);
    } catch (error) {
      console.error('ü§ñ [UnifiedAI] Error en an√°lisis de patrones:', error);
      return {
        patterns: [],
        urgentReview: [],
        recommendations: {
          immediate: ['Revisar gu√≠as con m√°s de 5 d√≠as en tr√°nsito'],
          shortTerm: ['Contactar clientes afectados'],
          strategic: ['Evaluar transportadoras'],
        },
        riskSummary: {
          totalAtRisk: 0,
          criticalCount: 0,
          estimatedLoss: 0,
          mainCauses: ['An√°lisis no disponible'],
        },
        colombianContext: {
          regionalIssues: [],
          carrierAlerts: [],
          seasonalFactors: [],
          marketInsights: [],
        },
      };
    }
  }

  /**
   * Generar mensaje para cliente
   */
  async generateCustomerMessage(
    guia: string,
    situation: string,
    tone: 'formal' | 'friendly' | 'urgent' = 'friendly'
  ): Promise<string> {
    const history = guideHistoryService.getHistory(guia);

    const prompt = `Genera un mensaje de WhatsApp para un cliente sobre su pedido.

DATOS DEL ENV√çO:
- Gu√≠a: ${guia}
- Estado: ${history?.currentStatusRaw || 'En proceso'}
- Transportadora: ${history?.transportadora || 'No especificada'}
- D√≠as en tr√°nsito: ${history?.metrics.diasEnTransito || 0}
- Situaci√≥n: ${situation}

TONO: ${tone === 'formal' ? 'Profesional y formal' : tone === 'urgent' ? 'Urgente pero respetuoso' : 'Cercano y amigable'}

REQUISITOS:
- M√°ximo 3 l√≠neas
- Sin saludos ni despedidas formales
- Incluir n√∫mero de gu√≠a
- Listo para enviar por WhatsApp
- En espa√±ol colombiano`;

    const response = await this.chat(prompt, []);
    return response.text;
  }

  /**
   * Obtener recomendaciones para gu√≠a espec√≠fica
   */
  async getGuideRecommendations(guia: string): Promise<string[]> {
    const history = guideHistoryService.getHistory(guia);

    if (!history) {
      return ['Gu√≠a no encontrada en el sistema'];
    }

    const prompt = `Analiza esta gu√≠a y dame 3-5 recomendaciones accionables:

GU√çA: ${guia}
ESTADO: ${history.currentStatusRaw}
TRANSPORTADORA: ${history.transportadora}
CIUDAD DESTINO: ${history.ciudadDestino}
D√çAS EN TR√ÅNSITO: ${history.metrics.diasEnTransito}
NOVEDAD: ${history.metrics.novedadActual || 'Ninguna'}
NIVEL DE RIESGO: ${history.riskLevel}

TIMELINE:
${history.timeline.slice(-5).map(e => `- ${e.timestamp}: ${e.description}`).join('\n')}

Dame recomendaciones espec√≠ficas y accionables, numeradas.`;

    const response = await this.chat(prompt, []);

    // Extraer recomendaciones numeradas
    const lines = response.text.split('\n').filter(l => /^\d+\./.test(l.trim()));
    return lines.length > 0 ? lines : [response.text];
  }
}

// Singleton
export const unifiedAI = new UnifiedAIService();
export default unifiedAI;
