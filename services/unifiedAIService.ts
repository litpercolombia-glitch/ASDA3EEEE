// services/unifiedAIService.ts
// Servicio Unificado de IA con Fallback Autom√°tico
// Soporta Claude, Gemini y OpenAI con cambio autom√°tico si uno falla

import { askAssistant as claudeAskAssistant } from './claudeService';
import { askAssistant as geminiAskAssistant } from './geminiService';
import { useAIConfigStore } from './aiConfigService';

// ============================================
// TIPOS DE MODO DE CHAT
// ============================================
export type ChatMode = 'fast' | 'reasoning';

export interface ChatModeConfig {
  id: ChatMode;
  name: string;
  description: string;
  icon: string;
  systemPromptAddition: string;
  temperature: number;
  maxTokens: number;
}

export const CHAT_MODES: Record<ChatMode, ChatModeConfig> = {
  fast: {
    id: 'fast',
    name: 'R√°pido',
    description: 'Respuestas concisas y directas',
    icon: '‚ö°',
    systemPromptAddition: `
MODO R√ÅPIDO - Responde de forma:
- Concisa (m√°ximo 2-3 oraciones)
- Directa al punto
- Sin explicaciones extensas
- Solo lo esencial`,
    temperature: 0.5,
    maxTokens: 500,
  },
  reasoning: {
    id: 'reasoning',
    name: 'Razonamiento',
    description: 'An√°lisis profundo paso a paso',
    icon: 'üß†',
    systemPromptAddition: `
MODO RAZONAMIENTO - Responde de forma:
- Anal√≠tica y detallada
- Paso a paso cuando sea necesario
- Con justificaci√≥n de tus conclusiones
- Considerando m√∫ltiples perspectivas
- Incluyendo pros y contras si aplica

Estructura tu respuesta:
1. **An√°lisis**: Eval√∫a la situaci√≥n
2. **Razonamiento**: Explica tu proceso de pensamiento
3. **Conclusi√≥n**: Da tu recomendaci√≥n final
4. **Siguientes pasos**: Acciones sugeridas`,
    temperature: 0.7,
    maxTokens: 2048,
  },
};

// ============================================
// FUNCI√ìN PARA LLAMAR A OPENAI
// ============================================
async function openaiAskAssistant(prompt: string, mode: ChatMode = 'fast'): Promise<string> {
  const config = useAIConfigStore.getState().providers.openai;
  const apiKey = config.apiKey;
  const modeConfig = CHAT_MODES[mode];

  if (!apiKey) {
    console.warn('OpenAI API Key no configurada');
    return '';
  }

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: config.model || 'gpt-4o-mini',
        max_tokens: modeConfig.maxTokens,
        temperature: modeConfig.temperature,
        messages: [
          {
            role: 'system',
            content: `Eres un EXPERTO EN LOG√çSTICA DE √öLTIMA MILLA EN COLOMBIA.
Trabajas para Litper Pro, una plataforma de gesti√≥n log√≠stica premium.
Siempre respondes en ESPA√ëOL COLOMBIANO de forma profesional.
${modeConfig.systemPromptAddition}`
          },
          { role: 'user', content: prompt }
        ],
      }),
    });

    if (!response.ok) {
      const error = await response.json();
      console.error('Error en OpenAI:', error);
      return '';
    }

    const data = await response.json();
    return data.choices?.[0]?.message?.content || '';
  } catch (error) {
    console.error('Error llamando a OpenAI:', error);
    return '';
  }
}

// ============================================
// TIPOS E INTERFACES
// ============================================

export type AIProvider = 'claude' | 'gemini' | 'openai';

export interface AIConfig {
  provider: AIProvider;
  temperature: number;
  maxTokens: number;
  systemPrompt: string;
}

export interface AIResponse {
  text: string;
  provider: AIProvider;
  confidence: number;
  processingTime: number;
  fallbackUsed: boolean;
  error?: string;
  metadata?: {
    tokensUsed?: number;
    model?: string;
  };
}

export interface ConversationContext {
  shipments: any[];
  recentQueries: string[];
}

// ============================================
// CONFIGURACI√ìN POR DEFECTO
// ============================================

const DEFAULT_CONFIGS: Record<AIProvider, AIConfig> = {
  claude: {
    provider: 'claude',
    temperature: 0.7,
    maxTokens: 4096,
    systemPrompt: `Eres un EXPERTO EN LOG√çSTICA DE √öLTIMA MILLA EN COLOMBIA.`,
  },
  gemini: {
    provider: 'gemini',
    temperature: 0.8,
    maxTokens: 4096,
    systemPrompt: `Eres un asistente de log√≠stica de Litper Pro.`,
  },
  openai: {
    provider: 'openai',
    temperature: 0.7,
    maxTokens: 4096,
    systemPrompt: `Eres un asistente profesional de log√≠stica.`,
  },
};

// Orden de fallback
const FALLBACK_ORDER: AIProvider[] = ['claude', 'gemini', 'openai'];

// ============================================
// SERVICIO UNIFICADO DE IA
// ============================================

class UnifiedAIService {
  private configs: Record<AIProvider, AIConfig> = { ...DEFAULT_CONFIGS };
  private currentProvider: AIProvider = 'claude';
  private recentQueries: string[] = [];
  private providerStatus: Record<AIProvider, { available: boolean; lastError?: string }> = {
    claude: { available: true },
    gemini: { available: true },
    openai: { available: true },
  };

  constructor() {
    console.log('ü§ñ [UnifiedAI] Servicio inicializado');
  }

  setProvider(provider: AIProvider): void {
    this.currentProvider = provider;
    console.log(`ü§ñ [UnifiedAI] Proveedor cambiado a: ${provider}`);
  }

  getProvider(): AIProvider {
    return this.currentProvider;
  }

  getProvidersStatus(): Record<AIProvider, { available: boolean; lastError?: string }> {
    return { ...this.providerStatus };
  }

  // ==================== CHAT PRINCIPAL ====================

  private currentMode: ChatMode = 'fast';

  setMode(mode: ChatMode): void {
    this.currentMode = mode;
    console.log(`ü§ñ [UnifiedAI] Modo cambiado a: ${mode}`);
  }

  getMode(): ChatMode {
    return this.currentMode;
  }

  getModeConfig(): ChatModeConfig {
    return CHAT_MODES[this.currentMode];
  }

  async chat(
    message: string,
    shipments: any[] = [],
    options?: {
      provider?: AIProvider;
      mode?: ChatMode;
      temperature?: number;
      includeHistory?: boolean;
    }
  ): Promise<AIResponse> {
    const startTime = Date.now();
    const provider = options?.provider || this.currentProvider;
    const mode = options?.mode || this.currentMode;

    // Agregar a queries recientes
    this.recentQueries.push(message);
    if (this.recentQueries.length > 10) {
      this.recentQueries.shift();
    }

    // Construir prompt con el modo seleccionado
    const enrichedPrompt = this.buildSimplePrompt(message, shipments, mode);

    // Intentar con el proveedor seleccionado
    let response = await this.callProvider(provider, enrichedPrompt, shipments, mode);

    // Si falla, intentar fallback
    if (response.error && !response.fallbackUsed) {
      console.log(`ü§ñ [UnifiedAI] ${provider} fall√≥, intentando fallback...`);
      response = await this.tryFallback(provider, enrichedPrompt, shipments, mode);
    }

    return {
      ...response,
      processingTime: Date.now() - startTime,
    };
  }

  private buildSimplePrompt(message: string, shipments: any[], mode: ChatMode): string {
    const modeConfig = CHAT_MODES[mode];
    const parts: string[] = [];

    // Contexto de env√≠os si hay
    if (shipments && shipments.length > 0) {
      const summary = shipments.slice(0, 20).map(s =>
        `- Gu√≠a: ${s.id || s.guia}, Estado: ${s.status || s.estado}, Transportadora: ${s.carrier || s.transportadora}`
      ).join('\n');

      parts.push('=== CONTEXTO DE GU√çAS ===');
      parts.push(`Total: ${shipments.length} env√≠os`);
      parts.push(summary);
      parts.push('');
    }

    // Mensaje del usuario
    parts.push('=== PREGUNTA DEL USUARIO ===');
    parts.push(message);
    parts.push('');

    // Instrucciones seg√∫n el modo
    parts.push(modeConfig.systemPromptAddition);

    return parts.join('\n');
  }

  // ==================== LLAMADAS A PROVEEDORES ====================

  private async callProvider(
    provider: AIProvider,
    prompt: string,
    shipments: any[],
    mode: ChatMode = 'fast'
  ): Promise<AIResponse> {
    try {
      let text: string = '';

      switch (provider) {
        case 'claude':
          text = await claudeAskAssistant(prompt);
          break;

        case 'gemini':
          try {
            const geminiResponse = await geminiAskAssistant(prompt, shipments);
            text = geminiResponse.text;
          } catch (e) {
            console.error('Error en Gemini:', e);
            text = '';
          }
          break;

        case 'openai':
          text = await openaiAskAssistant(prompt, mode);
          break;

        default:
          text = '';
      }

      // Verificar si la respuesta est√° vac√≠a
      if (!text || text.trim() === '') {
        console.warn(`ü§ñ [UnifiedAI] ${provider} retorn√≥ respuesta vac√≠a`);
        this.providerStatus[provider] = {
          available: false,
          lastError: 'Respuesta vac√≠a - posiblemente API key no configurada',
        };
        return {
          text: '',
          provider,
          confidence: 0,
          processingTime: 0,
          fallbackUsed: false,
          error: 'API key no configurada o respuesta vac√≠a',
        };
      }

      this.providerStatus[provider] = { available: true };

      return {
        text,
        provider,
        confidence: 0.8,
        processingTime: 0,
        fallbackUsed: false,
      };
    } catch (error: any) {
      console.error(`ü§ñ [UnifiedAI] Error con ${provider}:`, error.message);

      this.providerStatus[provider] = {
        available: false,
        lastError: error.message,
      };

      return {
        text: '',
        provider,
        confidence: 0,
        processingTime: 0,
        fallbackUsed: false,
        error: error.message,
      };
    }
  }

  private async tryFallback(
    failedProvider: AIProvider,
    prompt: string,
    shipments: any[],
    mode: ChatMode = 'fast'
  ): Promise<AIResponse> {
    const availableProviders = FALLBACK_ORDER.filter(p => p !== failedProvider);

    for (const provider of availableProviders) {
      console.log(`ü§ñ [UnifiedAI] Intentando fallback con: ${provider}`);
      const response = await this.callProvider(provider, prompt, shipments, mode);

      if (!response.error && response.text) {
        return {
          ...response,
          fallbackUsed: true,
        };
      }
    }

    // Todos fallaron - respuesta de emergencia
    return {
      text: this.getEmergencyResponse(),
      provider: 'claude',
      confidence: 0.3,
      processingTime: 0,
      fallbackUsed: true,
      error: 'Todos los proveedores de IA no est√°n disponibles',
    };
  }

  private getEmergencyResponse(): string {
    return `**Asistente no disponible temporalmente**

Para usar el chat de IA, necesitas configurar al menos una API key:

1. Ve a **Config** > **Conexiones IA**
2. Agrega tu API key de:
   - **Claude**: https://console.anthropic.com/
   - **Gemini**: https://aistudio.google.com/
   - **OpenAI**: https://platform.openai.com/

O configura las variables de entorno:
- \`VITE_ANTHROPIC_API_KEY\`
- \`VITE_GEMINI_API_KEY\`
- \`VITE_OPENAI_API_KEY\`

Mientras tanto, puedes usar las otras funciones de la plataforma.`;
  }

  // ==================== FUNCIONES AUXILIARES ====================

  async analyzeDelays(shipments: any[]): Promise<any> {
    return {
      patterns: [],
      urgentReview: [],
      recommendations: {
        immediate: ['Revisar gu√≠as con m√°s de 5 d√≠as en tr√°nsito'],
        shortTerm: ['Contactar clientes afectados'],
        strategic: ['Evaluar transportadoras'],
      },
    };
  }

  async generateCustomerMessage(
    guia: string,
    situation: string,
    tone: 'formal' | 'friendly' | 'urgent' = 'friendly'
  ): Promise<string> {
    const prompt = `Genera un mensaje corto de WhatsApp para un cliente sobre su pedido.
Gu√≠a: ${guia}
Situaci√≥n: ${situation}
Tono: ${tone === 'formal' ? 'Profesional' : tone === 'urgent' ? 'Urgente' : 'Amigable'}
M√°ximo 3 l√≠neas, sin saludos formales.`;

    const response = await this.chat(prompt, []);
    return response.text;
  }

  async getGuideRecommendations(guia: string): Promise<string[]> {
    return ['Verificar estado en la transportadora', 'Contactar al cliente'];
  }
}

// Singleton
export const unifiedAI = new UnifiedAIService();
export default unifiedAI;
